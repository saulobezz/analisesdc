{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns; sns.set(style='ticks', color_codes=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(\"../walmart-recruiting-store-sales-forecasting\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stores       = pd.read_csv(\"../walmart-recruiting-store-sales-forecasting/stores.csv\", sep=',',header=0)\n",
    "df_features     = pd.read_csv(\"../walmart-recruiting-store-sales-forecasting/features.csv\", sep=',',header=0)\n",
    "df_samplesub    = pd.read_csv(\"../walmart-recruiting-store-sales-forecasting/sampleSubmission.csv\", sep=',',header=0)\n",
    "df_train        = pd.read_csv(\"../walmart-recruiting-store-sales-forecasting/train.csv\", sep=',',header=0)\n",
    "df_test         = pd.read_csv(\"../walmart-recruiting-store-sales-forecasting/test.csv\", sep=',',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_stores_features = df_train.merge(df_stores,how='left').merge(df_features,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_stores_features['Date'] = pd.to_datetime(df_train_stores_features['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_stores_features = df_train_stores_features.drop(columns=['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_stores_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stores.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samplesub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samplesub.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorando os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_stores_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter(df_train_stores_features, column):\n",
    "    plt.figure()\n",
    "    plt.scatter(df_train_stores_features[column], df_train_stores_features['Weekly_Sales'])\n",
    "    plt.ylabel('weeklySales')\n",
    "    plt.xlabel(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_stores_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(df_train_stores_features, 'Fuel_Price')\n",
    "scatter(df_train_stores_features, 'Size')\n",
    "scatter(df_train_stores_features, 'CPI')\n",
    "scatter(df_train_stores_features, 'Type')\n",
    "scatter(df_train_stores_features, 'IsHoliday')\n",
    "scatter(df_train_stores_features, 'Unemployment')\n",
    "scatter(df_train_stores_features, 'Temperature')\n",
    "scatter(df_train_stores_features, 'Store')\n",
    "scatter(df_train_stores_features, 'Dept')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.Figure(figsize=(18,14))\n",
    "corr = df_train_stores_features.corr()\n",
    "c = plt.pcolor(corr)\n",
    "plt.yticks(np.arange(0.5, len(corr.index), 1), corr.index)\n",
    "plt.xticks(np.arange(0.5, len(corr.columns), 1), corr.columns)\n",
    "fig.colorbar(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_stores_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_train_stores_features,vars=['Weekly_Sales', 'Fuel_Price', 'Size', 'CPI', 'Dept', 'Temperature', 'Unemployment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(df_train_stores_features.fillna(0),vars=['Weekly_Sales', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in df_train_stores_features.groupby([\"Store\",\"Dept\"]):\n",
    "    plt.title(name)\n",
    "    plt.scatter(range(len(group)), group[\"Weekly_Sales\"])\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulando Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_stores_features = pd.get_dummies(df_train_stores_features, columns=[\"Type\"])\n",
    "df_train_stores_features[['MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']] = df_train_stores_features[['MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']].fillna(0)\n",
    "df_train_stores_features['Month'] = pd.to_datetime(df_train_stores_features['Date']).dt.month\n",
    "df_train_stores_features = df_train_stores_features.drop(columns=['Date','CPI','Fuel_Price','Unemployment','MarkDown3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_stores_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn():\n",
    "    knn = KNeighborsRegressor(n_neighbors=10)\n",
    "    return knn\n",
    "\n",
    "def extraTreesRegressor():\n",
    "    clf = ExtraTreesRegressor(n_estimators=100, max_features='sqrt', verbose=1, n_jobs=1)\n",
    "    return clf\n",
    "\n",
    "def randomForestRegressor():\n",
    "    clf = RandomForestRegressor(n_estimators=100 , max_features='log2', verbose=1)\n",
    "    return clf\n",
    "\n",
    "def svm():\n",
    "    clf = SVR(kernel='rgb', gamma='auto')\n",
    "    return clf\n",
    "\n",
    "def nn():\n",
    "    clf = MLPRegressor(hidden_layer_sizes=(10,), activation='relu', verbose=3)\n",
    "    return clf\n",
    "\n",
    "def predict_(m, test_x):\n",
    "    return pd.Series(m.predict(test_x))\n",
    "\n",
    "def model_():\n",
    "    return extraTreesRegressor()\n",
    "\n",
    "def train_(train_x, train_y):\n",
    "    m = model_()\n",
    "    m.fit(train_x, train_y)\n",
    "    return m\n",
    "\n",
    "def train_and_predict(train_x, train_y, test_x):\n",
    "    m = train_(train_x, train_y)\n",
    "    return predict_(m, test_x), m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(test_y, predicted, weights):\n",
    "    return mean_absolute_error(test_y, predicted, sample_weight=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "splited = []\n",
    "\n",
    "for name, group in df_train_stores_features.groupby(['Store', 'Dept']):\n",
    "    group = group.reset_index(drop=True)\n",
    "    trains_x = []\n",
    "    trains_y = []\n",
    "    tests_x = []\n",
    "    tests_y = []\n",
    "    if group.shape[0] <= 5:\n",
    "        f = np.array(range(5))\n",
    "        np.random.shuffle(f)\n",
    "        group['fold'] = f[:group.shape[0]]\n",
    "        continue\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf.split(group):\n",
    "        group.loc[test_index, 'fold'] = fold\n",
    "        fold += 1\n",
    "    splited.append(group)\n",
    "\n",
    "splited = pd.concat(splited).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splited.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "error_cv = 0\n",
    "best_error = np.iinfo(np.int32).max\n",
    "for fold in range(5):\n",
    "    df_train = splited.loc[splited['fold'] != fold]\n",
    "    df_test = splited.loc[splited['fold'] == fold]\n",
    "    train_y = df_train['Weekly_Sales']\n",
    "    train_x = df_train.drop(columns=['Weekly_Sales', 'fold'])\n",
    "    test_y = df_test['Weekly_Sales']\n",
    "    test_x = df_test.drop(columns=['Weekly_Sales', 'fold'])\n",
    "    print(df_train.shape, df_test.shape)\n",
    "    predicted, model = train_and_predict(train_x, train_y, test_x)\n",
    "    weights = test_x['IsHoliday'].replace(True,5).replace(False, 1)\n",
    "    error = calculate_error(test_y, predicted, weights)\n",
    "    error_cv += error\n",
    "    print(fold, error)\n",
    "    if error < best_error:\n",
    "        print('Find Best Model: ')\n",
    "        best_error = error\n",
    "        best_model = model\n",
    "error_cv /= 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
